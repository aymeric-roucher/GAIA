{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/aymeric/.cache/huggingface/modules/datasets_modules/datasets/gaia-benchmark--GAIA/ec492fe4320ee795b1aed6bb46229c5f693226b0f1316347501c24b4baeee005 (last modified on Tue May 28 10:04:32 2024) since it couldn't be found locally at gaia-benchmark/GAIA, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "eval_ds = datasets.load_dataset(\"gaia-benchmark/GAIA\", \"2023_all\")[\"validation\"]\n",
    "eval_ds = eval_ds.rename_columns(\n",
    "    {\"Question\": \"question\", \"Final answer\": \"true_answer\", \"Level\": \"task\"}\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_file_paths(row):\n",
    "    if len(row[\"file_name\"]) > 0:\n",
    "        row[\"file_name\"] = \"data/gaia/validation/\" + row[\"file_name\"]\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "eval_ds = eval_ds.map(preprocess_file_paths)\n",
    "\n",
    "eval_df = pd.DataFrame(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task\n",
       "2    86\n",
       "1    53\n",
       "3    26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df[\"task\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"extension\"] = eval_df[\"file_name\"].apply(lambda x: x.split(\".\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extension\n",
       "          127\n",
       "xlsx       13\n",
       "png         8\n",
       "mp3         3\n",
       "pdf         3\n",
       "zip         2\n",
       "jpg         2\n",
       "pdb         1\n",
       "jsonld      1\n",
       "docx        1\n",
       "txt         1\n",
       "pptx        1\n",
       "csv         1\n",
       "py          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df[\"extension\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/aymeric/.cache/huggingface/modules/datasets_modules/datasets/gaia-benchmark--GAIA/ec492fe4320ee795b1aed6bb46229c5f693226b0f1316347501c24b4baeee005 (last modified on Tue May 28 10:04:32 2024) since it couldn't be found locally at gaia-benchmark/GAIA, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "\n",
    "SET = \"test\"\n",
    "\n",
    "eval_ds = datasets.load_dataset(\"gaia-benchmark/GAIA\", \"2023_all\")[SET]\n",
    "eval_ds = eval_ds.rename_columns(\n",
    "    {\"Question\": \"question\", \"Final answer\": \"true_answer\", \"Level\": \"task\"}\n",
    ")\n",
    "eval_df = pd.DataFrame(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_json(\n",
    "    f\"output_gaia/{SET}/react_code_gpt4o_23-june_planning2_newprompt5_test.jsonl\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.evaluation.gaia_scorer import question_scorer\n",
    "\n",
    "results[\"is_correct\"] = results.apply(\n",
    "    lambda x: question_scorer(x[\"prediction\"], x[\"true_answer\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0033333333333333335"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"is_correct\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Reverse this ascii picture so that the fish is facing the opposite direction:\\n&gt;&gt;$()&gt;. Return the characters (without quotes) in a comma separated list.</td>\n",
       "      <td>.,&gt;,),(,$,&gt;,&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                     question  \\\n",
       "278  Reverse this ascii picture so that the fish is facing the opposite direction:\\n>>$()>. Return the characters (without quotes) in a comma separated list.   \n",
       "\n",
       "        prediction  \n",
       "278  .,>,),(,$,>,>  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results[\"is_correct\"], [\"question\", \"prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elements(x):\n",
    "    output = x[0][\"task\"]\n",
    "    for y in x[1:]:\n",
    "        try:\n",
    "            if \"observation\" in y:\n",
    "                output += y[\"llm_output\"] + \"\\nObservation:\" + y[\"observation\"]\n",
    "            else:\n",
    "                output += y[\"llm_output\"] + \"\\Error:\" + str(y[\"error\"])\n",
    "        except:\n",
    "            pass\n",
    "    return output\n",
    "\n",
    "\n",
    "results[\"reasoning_trace\"] = results[\"intermediate_steps\"].apply(\n",
    "    lambda x: get_elements(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[[\"question\", \"prediction\", \"reasoning_trace\"]].rename(\n",
    "    columns={\"prediction\": \"model_answer\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "results = results.merge(eval_df[[\"task_id\", \"question\"]], on=\"question\")\n",
    "results = results.drop_duplicates(subset=[\"task_id\"])\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[\n",
    "    [\"task_id\", \"model_answer\"]\n",
    "]  # [\"task_id\", \"model_answer\", \"reasoning_trace\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_json(\n",
    "    f\"gaia_{SET}_transformers_agents_gpt4o.jsonl\", orient=\"records\", lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aymeric/venvs/disposable/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (2.7.0)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from sentence-transformers) (4.41.0.dev0)\n",
      "Requirement already satisfied: tqdm in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: numpy in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from sentence-transformers) (0.23.0)\n",
      "Requirement already satisfied: Pillow in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/aymeric/venvs/disposable/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading faiss_cpu-1.8.0-cp310-cp310-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aymeric/venvs/disposable/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/aymeric/venvs/disposable/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]})\n",
    "    for doc in knowledge_base\n",
    "]\n",
    "\n",
    "docs_processed = RecursiveCharacterTextSplitter(chunk_size=500).split_documents(\n",
    "    source_docs\n",
    ")[:1000]\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "vectordb = FAISS.from_documents(documents=docs_processed, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sources = list(set([doc.metadata[\"source\"] for doc in docs_processed]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents:\n",
      "\n",
      "at+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct)\n",
      "===Document===\n",
      "BART](https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+wa\n",
      "===Document===\n",
      "В области NLP ( Обработка текстов на естественном языке ):\n",
      "- [Маскированное заполнение слов с помощью BERT](https://huggingface.co/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France)\n",
      "- [Распознавание сущностей с помощью Electra](https://huggingface.co/dbmdz/electra-large-discriminator-finetuned-conll03-english?text=My+name+is+Sarah+and+I+live+in+London+city)\n",
      "- [Генерация текста с помощью GPT-2](https://huggingface.co/gpt2?text=A+long+time+ago%2C+)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/spaces/m-ric/langchain-retriever-tool/commit/d1a0e494ff680e188cf41ab23194bfde5f4046ef', commit_message='Upload tool', commit_description='', oid='d1a0e494ff680e188cf41ab23194bfde5f4046ef', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from retriever_tool import RetrieverTool\n",
    "\n",
    "retriever_tool = RetrieverTool(vectordb, all_sources)\n",
    "print(retriever_tool(query=\"What is the capital of France?\"))\n",
    "retriever_tool.push_to_hub(repo_id=\"m-ric/langchain-retriever-tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.agents import Tool\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "import json\n",
    "\n",
    "\n",
    "all_sources = list(set([doc.metadata[\"source\"] for doc in docs_processed]))\n",
    "\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Retrieves some documents from the knowledge base that have the closest embeddings to the input query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"text\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        },\n",
    "        \"source\": {\n",
    "            \"type\": \"text\",\n",
    "            \"description\": f\"The source of the documents to search, as a str representation of a list. Possible values in the list are: {all_sources}. If this argument is not provided, all sources will be searched.\",\n",
    "        },\n",
    "    }\n",
    "    output_type = \"text\"\n",
    "\n",
    "    def __init__(self, vectordb: VectorStore, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vectordb = vectordb\n",
    "\n",
    "    def forward(self, query: str, source: str = str(all_sources)) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        if isinstance(source, str) and \"[\" not in str(\n",
    "            source\n",
    "        ):  # if the source is not representing a list\n",
    "            source = [source]\n",
    "        source = json.loads(str(source).replace(\"'\", '\"'))\n",
    "\n",
    "        docs = self.vectordb.similarity_search(query, filter={\"source\": source}, k=3)\n",
    "\n",
    "        if len(docs) == 0:\n",
    "            return \"No documents found with this filtering. Try removing the source filter.\"\n",
    "        return \"Retrieved documents:\\n\\n\" + \"\\n===Document===\\n\".join(\n",
    "            [doc.page_content for doc in docs]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Retrieved documents:\\n\\nat+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct)\\n===Document===\\nBART](https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+wa\\n===Document===\\nВ области NLP ( Обработка текстов на естественном языке ):\\n- [Маскированное заполнение слов с помощью BERT](https://huggingface.co/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France)\\n- [Распознавание сущностей с помощью Electra](https://huggingface.co/dbmdz/electra-large-discriminator-finetuned-conll03-english?text=My+name+is+Sarah+and+I+live+in+London+city)\\n- [Генерация текста с помощью GPT-2](https://huggingface.co/gpt2?text=A+long+time+ago%2C+)'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RetrieverTool(vectordb)(query=\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vectordb': <langchain_community.vectorstores.faiss.FAISS object at 0x3acdc95d0>, 'all_sources': ['datasets', 'evaluate', 'blog', 'hf-endpoints-documentation', 'diffusers', 'datasets-server', 'transformers', 'optimum', 'pytorch-image-models', 'gradio', 'deep-rl-class', 'course', 'peft', 'hub-docs']}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "from transformers.agents import Tool\n",
    "\n",
    "retriever_tool = Tool.from_hub(\n",
    "    repo_id=\"m-ric/langchain-retriever-tool\", vectordb=vectordb, all_sources=all_sources\n",
    ")\n",
    "\n",
    "other_tool = Tool.from_hub(repo_id=\"m-ric/hf-model-downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Retrieved documents:\\n\\nat+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct)\\n===Document===\\nBART](https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+wa\\n===Document===\\nВ области NLP ( Обработка текстов на естественном языке ):\\n- [Маскированное заполнение слов с помощью BERT](https://huggingface.co/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France)\\n- [Распознавание сущностей с помощью Electra](https://huggingface.co/dbmdz/electra-large-discriminator-finetuned-conll03-english?text=My+name+is+Sarah+and+I+live+in+London+city)\\n- [Генерация текста с помощью GPT-2](https://huggingface.co/gpt2?text=A+long+time+ago%2C+)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool(query=\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m======== New task ========\u001b[0m\n",
      "\u001b[37;1mPlease show me a LORA finetuning script\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'retriever' with arguments: {'query': 'LORA finetuning script', 'source': \"['transformers', 'hf-endpoints-documentation']\"}\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'retriever' with arguments: {'query': 'LORA finetuning script'}\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'retriever' with arguments: {'query': 'LORA finetuning script', 'source': 'github.com/huggingface/diffusers/blob/main/examples/text_to_image/text_to_image_lora.py'}\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'final_answer' with arguments: {'answer': 'https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/text_to_image_lora.py'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output:\n",
      "https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/text_to_image_lora.py\n"
     ]
    }
   ],
   "source": [
    "from transformers.agents import HfEngine, ReactJsonAgent\n",
    "\n",
    "llm_engine = HfEngine(\"meta-llama/Meta-Llama-3-70B-Instruct\")\n",
    "\n",
    "agent = ReactJsonAgent(\n",
    "    tools=[RetrieverTool(vectordb, all_sources)], llm_engine=llm_engine\n",
    ")\n",
    "\n",
    "agent_output = agent.run(\"Please show me a LORA finetuning script\")\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
